{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_ml_method.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj_C7ygXvIhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install nvidia-smi\n",
        "# !pip install google-colab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULsK-asvdcns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google import auth\n",
        "auth.default()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'Team18-10605-Final-Project'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzHpcj1bdy7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!sudo curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!sudo apt -qq update\n",
        "!sudo apt -qq install gcsfuse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoiivX8O0Xe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir bucket\n",
        "!gcsfuse bucket-team18-10605-final bucket"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPgj3FWKhae5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "import numpy as np\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow_addons.metrics import RSquare\n",
        "\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fmZ7I1KQkEK",
        "colab_type": "text"
      },
      "source": [
        "Load Data in tf.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSzLgwJ-l8gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_outliers(features, label):\n",
        "  # label\n",
        "  if not (-7.0 <= label and label <= 103.0):\n",
        "    return False\n",
        "  # p_score\n",
        "  tmp = features[-2] * 13.664352804935564 + 5.390716682669022\n",
        "  if not (-7.0 <= tmp and tmp <= 103.0):\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "def normalize(vals):\n",
        "    # num_words\n",
        "    vals[-1] = (vals[-1] - 17.13712707395722)/32.30891863874633\n",
        "    # p_score\n",
        "    vals[-2] = (vals[-2] - 5.390716682669022)/13.664352804935564\n",
        "    # p_time\n",
        "    vals[-4] = (vals[-4] - 9761.223722159446)/50008.29178605555\n",
        "    return vals\n",
        "\n",
        "def one_hot(vals):\n",
        "    ohe = np.zeros((100,))\n",
        "    subreddit_id = int(vals[0])\n",
        "    ohe[subreddit_id] = 1.0\n",
        "    return np.concatenate((ohe, vals[1:]))\n",
        "  \n",
        "def process(arr):  \n",
        "    return one_hot(normalize(arr))\n",
        "\n",
        "def get_dataset(filepath_pattern):    \n",
        "    def parse_line(line): \n",
        "      line = tf.strings.split(line, \",\")\n",
        "      line = tf.strings.to_number(line)      \n",
        "      label = line[0]\n",
        "      features = line[1:]\n",
        "\n",
        "      features = tf.numpy_function(process, [features], tf.double)\n",
        "      label = tf.reshape(label, [1])\n",
        "      features = tf.reshape(features, [157])\n",
        "      return (features, label)\n",
        "    ds = tf.data.Dataset.list_files(filepath_pattern)\n",
        "    ds = tf.data.TextLineDataset(ds)\n",
        "    ds = ds.map(parse_line)\n",
        "    ds = ds.filter(lambda features, label: filter_outliers(features, label))\n",
        "    return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk1EBfjfQe5e",
        "colab_type": "text"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP2XqKDP4M3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " train_ds = get_dataset(\"bucket/full_processed_train/part-*\").batch(128).cache() \n",
        "val_ds = get_dataset(\"bucket/full_processed_val/part-*\").batch(128).cache()  \n",
        "test_ds = get_dataset(\"bucket/full_processed_test/part-*\").batch(128).cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYjNTKxtQcXO",
        "colab_type": "text"
      },
      "source": [
        "Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB5KvDGi3HNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configuration dict\n",
        "config = {\n",
        "    'n_layers': 2,\n",
        "    'h_dim': 128,\n",
        "    'lr': 0.0001,\n",
        "    'decay': 1e-6,\n",
        "    'bs': 32,        \n",
        "    'epochs': 30\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcH2Ilh8PjzW",
        "colab_type": "text"
      },
      "source": [
        "Model Training with tf.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFMlC4UE6VFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model structure\n",
        "model = models.Sequential()\n",
        "for i in range(config['n_layers']):\n",
        "    model.add(Dense(config['h_dim']))\n",
        "    model.add(Activation('relu'))\n",
        "model.add(Dense(1))\n",
        "model.build((None, 157))\n",
        "print(model.summary())\n",
        "\n",
        "# define optimizer and loss function\n",
        "optim = keras.optimizers.Adam(learning_rate=config['lr'], decay=config['decay'])\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# # Checkpointing weights \n",
        "checkpoint_dir = \"model\"\n",
        "monitor = \"val_root_mean_squared_error\"\n",
        "checkpoint_path = checkpoint_dir + \"/model.{epoch:03d}-{%s:.4f}.hdf5\" % monitor\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 monitor=monitor,\n",
        "                                                 save_weights_only=False,\n",
        "                                                 save_best_only=False,\n",
        "                                                 verbose=1)\n",
        "\n",
        "callbacks = [cp_callback] \n",
        "\n",
        "# compile\n",
        "model.compile(optimizer=optim, loss=loss_fn, metrics=['mae', RSquare(), RootMeanSquaredError()])\n",
        "model.fit(train_ds, epochs=config['epochs'], validation_data=val_ds, callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUBbVjMbQTqI",
        "colab_type": "text"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWwMulHY3YDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.evaluate(test_ds)\n",
        "print('Test MAE: {}\\n Test r2: {}\\n Test RMSE: {}'.format(result[1], result[2], result[3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCjLcluh3b6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to bucket\n",
        "model.save_weights(\"bucket/model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}