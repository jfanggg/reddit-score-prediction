{"cells":[{"cell_type":"code","source":["%matplotlib inline"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# IMPORTS\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.regression import LinearRegression, LinearRegressionModel, RandomForestRegressor, RandomForestRegressionModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.linalg import SparseVector\nfrom pyspark.sql.types import IntegerType\nimport matplotlib.pyplot as plt\nimport numpy as np"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["def parse_csv(s):\n  return list(map(float, s.split(',')))\n\ndef extract_relevant_feats(vals):\n  return {\n    'label': int(vals[0]),\n    'num_words': float(vals[-1]),\n    'p_score': float(vals[-2]),\n    'p_time': float(vals[-4])\n  }\n  \ndef read_csv(filepath):\n  return (sc.textFile(filepath, minPartitions=96)\n          .map(parse_csv)\n          .map(extract_relevant_feats)\n          .toDF())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["path = \"mnt/blobmount/\"\ndf = read_csv(path + \"full_processed_train\").cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/session.py:375: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n  warnings.warn(&#34;Using RDD of dict to inferSchema is deprecated. &#34;\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["### Outlier Removal"],"metadata":{}},{"cell_type":"code","source":["minimum = df.selectExpr('MIN(label)').take(1)[0][0]\nmaximum = df.selectExpr('MAX(label)').take(1)[0][0]\nbot_percentile = df.selectExpr('percentile(label, 0.01)').take(1)[0][0]\ntop_percentile = df.selectExpr('percentile(label, 0.99)').take(1)[0][0]\n\nprint('minimum: ', minimum)\nprint('maximum: ', maximum)\nprint('0.01 percentile: ', bot_percentile)\nprint('0.99 percentile: ', top_percentile)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">minimum:  -31171\nmaximum:  57953\n0.01 percentile:  -7.0\n0.99 percentile:  103.0\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["filtered_df = (df.filter(bot_percentile <= df.label).filter(df.label <= top_percentile)\n               .filter(bot_percentile <= df.p_score).filter(df.p_score <= top_percentile))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["### Features"],"metadata":{}},{"cell_type":"code","source":["for feat in ['label', 'num_words', 'p_score', 'p_time']:\n  print(feat)\n  avg = filtered_df.selectExpr('AVG({})'.format(feat)).take(1)[0][0]\n  std = filtered_df.selectExpr('STD({})'.format(feat)).take(1)[0][0]\n  print('average: ', avg)\n  print('std: ', std)\n  print()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">label\naverage:  4.187128850055533\nstd:  8.675358078926514\n\nnum_words\naverage:  17.130885717886557\nstd:  32.14070571476776\n\np_score\naverage:  5.388701700546126\nstd:  13.664664527154423\n\np_time\naverage:  9757.345945283152\nstd:  50103.77313992664\n\n</div>"]}}],"execution_count":9}],"metadata":{"name":"data_exploration","notebookId":3461252564448009},"nbformat":4,"nbformat_minor":0}
